{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from skimage.feature import hog\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data set image paths for both positive and negative domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Veh_Imgs_Path = \"./../udacity_dataset/vehicles/vehicles/\"\n",
    "NonVeh_Imgs_Path = \"./../udacity_dataset/non_vehicles/non_vehicles/\"\n",
    "\n",
    "Veh_Imgs = os.listdir(Veh_Imgs_Path)\n",
    "NonVeh_Imgs = os.listdir(NonVeh_Imgs_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Data set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CollectImages(folderpath, ImagePaths, isLabeled = True):\n",
    "    images = []\n",
    "    for ImagePath in ImagePaths:\n",
    "        if (len(ImagePath.split('.')) == 2):\n",
    "            im = cv2.imread(folderpath + ImagePath)\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            #print('Image ' , ImagePath , ' is: ', type(im), ' with dimensions: ', im.shape)\n",
    "            if isLabeled == True:\n",
    "                images.append((im, ImagePath.split('.')[0]))\n",
    "            else:\n",
    "                images.append(im)\n",
    "        else:\n",
    "            print('Image', ImagePath, 'is correupted --> Discarded.')\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Image Set has  8792\n",
      "Non Car Image Set has  8968\n"
     ]
    }
   ],
   "source": [
    "CarImageSet = []\n",
    "NonCarImageSet = []\n",
    "\n",
    "for folder in Veh_Imgs:\n",
    "    folderpath = Veh_Imgs_Path + folder\n",
    "    Carsimagespath = os.listdir(folderpath)\n",
    "    CarImageSet.append(CollectImages(folderpath + '/', Carsimagespath, True))\n",
    "\n",
    "for folder in NonVeh_Imgs:\n",
    "    folderpath = NonVeh_Imgs_Path + folder\n",
    "    NonCarsimagespath = os.listdir(folderpath)\n",
    "    NonCarImageSet.append(CollectImages(folderpath + '/', NonCarsimagespath, True))\n",
    "\n",
    "CarImageSet = np.concatenate(CarImageSet)\n",
    "NonCarImageSet = np.concatenate(NonCarImageSet)\n",
    "\n",
    "print('Car Image Set has ', str(len(CarImageSet)))\n",
    "print('Non Car Image Set has ', str(len(NonCarImageSet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define to access both image pixel values and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgPxlVal = 0\n",
    "img_Label = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pltImages(images, labels, nrows = 1, ncols = 2, fig_w = 20, fig_h = 10, isgray = False):\n",
    "    #below code is inspired from https://stackoverflow.com/questions/17111525/how-to-show-multiple-images-in-one-figure\n",
    "    assert len(images) <= (nrows * ncols)\n",
    "    if labels != \"\":\n",
    "        assert len(images) == len(labels)\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "    \n",
    "    for index in range(len(images)):\n",
    "        plot = fig.add_subplot(nrows,ncols,index+1)\n",
    "        if labels != \"\":\n",
    "            plot.set_title(labels[index])\n",
    "        if(isgray == False):\n",
    "            plt.imshow(images[index].squeeze())\n",
    "        else:\n",
    "            plt.imshow(images[index].squeeze(), cmap='gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis_imgs = []\n",
    "vis_labels = []\n",
    "\n",
    "#show 12 random images from Car dataset\n",
    "for i in range(12):\n",
    "    index = randint(0, len(CarImageSet))\n",
    "    vis_imgs.append(CarImageSet[index][imgPxlVal])\n",
    "    vis_labels.append('Car')\n",
    "\n",
    "#show 12 random images from Not Car dataset\n",
    "for i in range(12):\n",
    "    index = randint(0, len(NonCarImageSet))\n",
    "    vis_imgs.append(NonCarImageSet[index][imgPxlVal])\n",
    "    vis_labels.append('Not Car')\n",
    "\n",
    "pltImages(vis_imgs, vis_labels, 2, 12, 16, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize color space features using histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pltHistograms(hists, labels, nrows = 1, ncols = 2, fig_w = 20, fig_h = 10, xlim = [0,256]):\n",
    "    assert len(hists) == len(labels)\n",
    "    assert len(hists) <= (nrows * ncols)\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "    \n",
    "    for index in range(len(hists)):\n",
    "        plot = fig.add_subplot(nrows,ncols,index+1)\n",
    "        plot.set_title(labels[index])\n",
    "        plt.plot(hists[index])\n",
    "        plt.xlim(xlim)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Channel_0 = 0\n",
    "Channel_1 = 1\n",
    "Channel_2 = 2\n",
    "\n",
    "histSize = [48]\n",
    "histrange = [0,255]\n",
    "\n",
    "ColorSpace = ['RGB','HSV','HLS', 'LAB', 'YUV', 'LUV', 'YCrCb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExploreColorSpaceHistogram(img):\n",
    "    hist = []\n",
    "    hist_label = []\n",
    "\n",
    "    hist_0 = cv2.calcHist(img,[Channel_0],None,histSize,histrange)\n",
    "    hist_1 = cv2.calcHist(img,[Channel_1],None,histSize,histrange)\n",
    "    hist_2 = cv2.calcHist(img,[Channel_2],None,histSize,histrange)\n",
    "    hist.append(hist_0)\n",
    "    hist_label.append(\"RGB_Channel 0\")\n",
    "    hist.append(hist_1)\n",
    "    hist_label.append(\"RGB_Channel 1\")\n",
    "    hist.append(hist_2)\n",
    "    hist_label.append(\"RGB_Channel 2\")\n",
    "\n",
    "    HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hist_0 = cv2.calcHist(HSV,[Channel_0],None,histSize,histrange)\n",
    "    hist_1 = cv2.calcHist(HSV,[Channel_1],None,histSize,histrange)\n",
    "    hist_2 = cv2.calcHist(HSV,[Channel_2],None,histSize,histrange)\n",
    "    hist.append(hist_0)\n",
    "    hist_label.append(\"HSV_Channel 0\")\n",
    "    hist.append(hist_1)\n",
    "    hist_label.append(\"HSV_Channel 1\")\n",
    "    hist.append(hist_2)\n",
    "    hist_label.append(\"HSV_Channel 2\")\n",
    "\n",
    "    HLS = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    hist_0 = cv2.calcHist(HLS,[Channel_0],None,histSize,histrange)\n",
    "    hist_1 = cv2.calcHist(HLS,[Channel_1],None,histSize,histrange)\n",
    "    hist_2 = cv2.calcHist(HLS,[Channel_2],None,histSize,histrange)\n",
    "    hist.append(hist_0)\n",
    "    hist_label.append(\"HLS_Channel 0\")\n",
    "    hist.append(hist_1)\n",
    "    hist_label.append(\"HLS_Channel 1\")\n",
    "    hist.append(hist_2)\n",
    "    hist_label.append(\"HLS_Channel 2\")\n",
    "\n",
    "    LAB = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    hist_0 = cv2.calcHist(LAB,[Channel_0],None,histSize,histrange)\n",
    "    hist_1 = cv2.calcHist(LAB,[Channel_1],None,histSize,histrange)\n",
    "    hist_2 = cv2.calcHist(LAB,[Channel_2],None,histSize,histrange)\n",
    "    hist.append(hist_0)\n",
    "    hist_label.append(\"LAB_Channel 0\")\n",
    "    hist.append(hist_1)\n",
    "    hist_label.append(\"LAB_Channel 1\")\n",
    "    hist.append(hist_2)\n",
    "    hist_label.append(\"LAB_Channel 2\")\n",
    "\n",
    "    YUV = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "    hist_0 = cv2.calcHist(YUV,[Channel_0],None,histSize,histrange)\n",
    "    hist_1 = cv2.calcHist(YUV,[Channel_1],None,histSize,histrange)\n",
    "    hist_2 = cv2.calcHist(YUV,[Channel_2],None,histSize,histrange)\n",
    "    hist.append(hist_0)\n",
    "    hist_label.append(\"YUV_Channel 0\")\n",
    "    hist.append(hist_1)\n",
    "    hist_label.append(\"YUV_Channel 1\")\n",
    "    hist.append(hist_2)\n",
    "    hist_label.append(\"YUV_Channel 2\")\n",
    "\n",
    "    LUV = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "\n",
    "    hist_0 = cv2.calcHist(LUV,[Channel_0],None,histSize,histrange)\n",
    "    hist_1 = cv2.calcHist(LUV,[Channel_1],None,histSize,histrange)\n",
    "    hist_2 = cv2.calcHist(LUV,[Channel_2],None,histSize,histrange)\n",
    "    hist.append(hist_0)\n",
    "    hist_label.append(\"LUV_Channel 0\")\n",
    "    hist.append(hist_1)\n",
    "    hist_label.append(\"LUV_Channel 1\")\n",
    "    hist.append(hist_2)\n",
    "    hist_label.append(\"LUV_Channel 2\")\n",
    "    \n",
    "    YCrCb = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "    hist_0 = cv2.calcHist(YCrCb,[Channel_0],None,histSize,histrange)\n",
    "    hist_1 = cv2.calcHist(YCrCb,[Channel_1],None,histSize,histrange)\n",
    "    hist_2 = cv2.calcHist(YCrCb,[Channel_2],None,histSize,histrange)\n",
    "    hist.append(hist_0)\n",
    "    hist_label.append(\"YCrCb_Channel 0\")\n",
    "    hist.append(hist_1)\n",
    "    hist_label.append(\"YCrCb_Channel 1\")\n",
    "    hist.append(hist_2)\n",
    "    hist_label.append(\"YCrCb_Channel 2\")\n",
    "\n",
    "    pltHistograms(hist, hist_label, 7, 3, xlim = [0, histSize[0]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CarImageIndex = 0\n",
    "CarImageIndex = randint(0, len(CarImageSet))\n",
    "CarImage = [CarImageSet[CarImageIndex][imgPxlVal]]\n",
    "CarImageLabel = [CarImageSet[CarImageIndex][img_Label]]\n",
    "\n",
    "pltImages(CarImage, CarImageLabel, 1, 1)\n",
    "ExploreColorSpaceHistogram(CarImage[0])\n",
    "\n",
    "#NonCarImageIndex = 0\n",
    "NonCarImageIndex = randint(0, len(NonCarImageSet))\n",
    "NonCarImage = [NonCarImageSet[NonCarImageIndex][imgPxlVal]]\n",
    "NonCarImageLabel = [NonCarImageSet[NonCarImageIndex][img_Label]]\n",
    "\n",
    "pltImages(NonCarImage, NonCarImageLabel, 1, 1)\n",
    "ExploreColorSpaceHistogram(NonCarImage[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code obtained from Udacity lesson 16\n",
    "def bin_spatial_Demo_colorspace(img, color_space='RGB', size=(32, 32)):\n",
    "    # Convert image to new color space (if specified)\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'LAB':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)             \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(feature_image, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size=(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis_imgs = []\n",
    "vis_labels = []\n",
    "\n",
    "index = randint(0, len(CarImageSet))\n",
    "\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(CarImageSet[index][imgPxlVal], size=size))\n",
    "vis_labels.append('RGB')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(CarImageSet[index][imgPxlVal], color_space='HSV', size=size))\n",
    "vis_labels.append('HSV')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(CarImageSet[index][imgPxlVal], color_space='LUV', size=size))\n",
    "vis_labels.append('LUV')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(CarImageSet[index][imgPxlVal], color_space='HLS', size=size))\n",
    "vis_labels.append('HLS')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(CarImageSet[index][imgPxlVal], color_space='YUV', size=size))\n",
    "vis_labels.append('YUV')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(CarImageSet[index][imgPxlVal], color_space='YCrCb', size=size))\n",
    "vis_labels.append('YCrCb')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(CarImageSet[index][imgPxlVal], color_space='LAB', size=size))\n",
    "vis_labels.append('LAB')\n",
    "\n",
    "pltImages([CarImageSet[index][imgPxlVal]], [\"Original Image\"], 1, 1, 20, 2)\n",
    "pltHistograms(vis_imgs, vis_labels, 7, 1, xlim = [0, 200])\n",
    "\n",
    "vis_imgs = []\n",
    "vis_labels = []\n",
    "\n",
    "index = randint(0, len(NonCarImageSet))\n",
    "\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(NonCarImageSet[index][imgPxlVal], size=size))\n",
    "vis_labels.append('RGB')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(NonCarImageSet[index][imgPxlVal], color_space='HSV', size=size))\n",
    "vis_labels.append('HSV')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(NonCarImageSet[index][imgPxlVal], color_space='LUV', size=size))\n",
    "vis_labels.append('LUV')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(NonCarImageSet[index][imgPxlVal], color_space='HLS', size=size))\n",
    "vis_labels.append('HLS')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(NonCarImageSet[index][imgPxlVal], color_space='YUV', size=size))\n",
    "vis_labels.append('YUV')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(NonCarImageSet[index][imgPxlVal], color_space='YCrCb', size=size))\n",
    "vis_labels.append('YCrCb')\n",
    "vis_imgs.append(bin_spatial_Demo_colorspace(NonCarImageSet[index][imgPxlVal], color_space='LAB', size=size))\n",
    "vis_labels.append('LAB')\n",
    "\n",
    "pltImages([NonCarImageSet[index][imgPxlVal]], [\"Original Image\"], 1, 1, 20, 2)\n",
    "pltHistograms(vis_imgs, vis_labels, 7, 1, xlim = [0, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I started with resize to 32*32 but the output proved to be very large, 3072, which I consider very large for a soft qualifier like this and better to be downsampled to 8*8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All color spaces provide different signatures between the two classes, take RGB for simplicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize HOG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features_demo(img, orient, pix_per_cell, cell_per_block, blockNorm, trns_sqrt, visualize=False, feature_vec=True):\n",
    "    if visualize == True:\n",
    "        features, hog_im = hog(img,\n",
    "                               orientations=orient,\n",
    "                               pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                               cells_per_block=(cell_per_block, cell_per_block),\n",
    "                               block_norm = blockNorm, #Block Normalize didn't show any change effect on image\n",
    "                               transform_sqrt=trns_sqrt, \n",
    "                               visualise=visualize,\n",
    "                               feature_vector=feature_vec)\n",
    "        return features, hog_im\n",
    "    else:      \n",
    "        features = hog(img,\n",
    "                       orientations=orient,\n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       block_norm = blockNorm, #Block Normalize didn't show any change effect on image\n",
    "                       transform_sqrt=trns_sqrt, \n",
    "                       visualise=visualize,\n",
    "                       feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orient = 8\n",
    "pix_per_cell = 16\n",
    "cells_per_block = 2\n",
    "TransformSqrt = True\n",
    "\n",
    "blockNorm = ['L1', 'L1-sqrt', 'L2', 'L2-Hys']\n",
    "\n",
    "hc = 'ALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VisauliseHOG(img):\n",
    "    vis = True\n",
    "    __, hog_im = get_hog_features_demo(\n",
    "        img,\n",
    "        orient,\n",
    "        pix_per_cell,\n",
    "        cells_per_block,\n",
    "        'L2-Hys',\n",
    "        visualize=vis,\n",
    "        trns_sqrt=TransformSqrt,\n",
    "        feature_vec=False)\n",
    "    return hog_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ExploreHOGSpace(img):\n",
    "    HOG_IMs = []\n",
    "    hog_label = []\n",
    "    \n",
    "    hog_0 = VisauliseHOG(img[:,:,Channel_0])\n",
    "    hog_1 = VisauliseHOG(img[:,:,Channel_1])\n",
    "    hog_2 = VisauliseHOG(img[:,:,Channel_2])\n",
    "    pltImages([hog_0], [\"RGB_Channel 0\"], 1, 1)\n",
    "    pltImages([hog_1], [\"RGB_Channel 1\"], 1, 1)\n",
    "    pltImages([hog_2], [\"RGB_Channel 2\"], 1, 1)\n",
    "\n",
    "    HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hog_0 = VisauliseHOG(HSV[:,:,Channel_0])\n",
    "    hog_1 = VisauliseHOG(HSV[:,:,Channel_1])\n",
    "    hog_2 = VisauliseHOG(HSV[:,:,Channel_2])\n",
    "    pltImages([hog_0], [\"HSV_Channel 0\"], 1, 1)\n",
    "    pltImages([hog_1], [\"HSV_Channel 1\"], 1, 1)\n",
    "    pltImages([hog_2], [\"HSV_Channel 2\"], 1, 1)\n",
    "\n",
    "    HLS = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    hog_0 = VisauliseHOG(HLS[:,:,Channel_0])\n",
    "    hog_1 = VisauliseHOG(HLS[:,:,Channel_1])\n",
    "    hog_2 = VisauliseHOG(HLS[:,:,Channel_2])\n",
    "    pltImages([hog_0], [\"HLS_Channel 0\"], 1, 1)\n",
    "    pltImages([hog_1], [\"HLS_Channel 1\"], 1, 1)\n",
    "    pltImages([hog_2], [\"HLS_Channel 2\"], 1, 1)\n",
    "\n",
    "    LAB = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    hog_0 = VisauliseHOG(LAB[:,:,Channel_0])\n",
    "    hog_1 = VisauliseHOG(LAB[:,:,Channel_1])\n",
    "    hog_2 = VisauliseHOG(LAB[:,:,Channel_2])\n",
    "    pltImages([hog_0], [\"LAB_Channel 0\"], 1, 1)\n",
    "    pltImages([hog_1], [\"LAB_Channel 1\"], 1, 1)\n",
    "    pltImages([hog_2], [\"LAB_Channel 2\"], 1, 1)\n",
    "\n",
    "    YUV = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "    hog_0 = VisauliseHOG(YUV[:,:,Channel_0])\n",
    "    hog_1 = VisauliseHOG(YUV[:,:,Channel_1])\n",
    "    hog_2 = VisauliseHOG(YUV[:,:,Channel_2])\n",
    "    pltImages([hog_0], [\"YUV_Channel 0\"], 1, 1)\n",
    "    pltImages([hog_1], [\"YUV_Channel 1\"], 1, 1)\n",
    "    pltImages([hog_2], [\"YUV_Channel 2\"], 1, 1)\n",
    "\n",
    "    LUV = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "\n",
    "    hog_0 = VisauliseHOG(LUV[:,:,Channel_0])\n",
    "    hog_1 = VisauliseHOG(LUV[:,:,Channel_1])\n",
    "    hog_2 = VisauliseHOG(LUV[:,:,Channel_2])\n",
    "    pltImages([hog_0], [\"LUV_Channel 0\"], 1, 1)\n",
    "    pltImages([hog_1], [\"LUV_Channel 1\"], 1, 1)\n",
    "    pltImages([hog_2], [\"LUV_Channel 2\"], 1, 1)\n",
    "    \n",
    "    YCrCb = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "    hog_0 = VisauliseHOG(YCrCb[:,:,Channel_0])\n",
    "    hog_1 = VisauliseHOG(YCrCb[:,:,Channel_1])\n",
    "    hog_2 = VisauliseHOG(YCrCb[:,:,Channel_2])\n",
    "    pltImages([hog_0], [\"YCrCb_Channel 0\"], 1, 1)\n",
    "    pltImages([hog_1], [\"YCrCb_Channel 1\"], 1, 1)\n",
    "    pltImages([hog_2], [\"YCrCb_Channel 2\"], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CarImageIndex = 0\n",
    "#CarImageIndex = randint(0, len(CarImageSet))\n",
    "HOGCarImage = [CarImageSet[CarImageIndex][imgPxlVal]]\n",
    "HOGCarImageLabel = [CarImageSet[CarImageIndex][img_Label]]\n",
    "\n",
    "pltImages(HOGCarImage, HOGCarImageLabel, 1, 1)\n",
    "ExploreHOGSpace(HOGCarImage[0])\n",
    "\n",
    "NonCarImageIndex = 0\n",
    "#NonCarImageIndex = randint(0, len(NonCarImageSet))\n",
    "HOGNonCarImage = [NonCarImageSet[NonCarImageIndex][imgPxlVal]]\n",
    "HOGCarImageLabel = [CarImageSet[CarImageIndex][img_Label]]\n",
    "\n",
    "pltImages(HOGNonCarImage, HOGCarImageLabel, 1, 1)\n",
    "ExploreHOGSpace(HOGNonCarImage[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enough Visualization :D, Let's Extract Some Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AllowedColorSpace = ['RGB','HSV','HLS', 'LAB', 'YUV', 'LUV', 'YCrCb']\n",
    "AllowedblockNorm = ['L1', 'L1-sqrt', 'L2', 'L2-Hys']\n",
    "\n",
    "#Calibration Parameters\n",
    "CHist_EN=False\n",
    "SB_EN=False\n",
    "HOG_EN=True\n",
    "Nrmlz=False\n",
    "\n",
    "#Color Histogram\n",
    "histSize = [48]\n",
    "histrange = [0,255]\n",
    "Hist_colorspace = \"RGB\"\n",
    "CS_Ch_Idx = \"All\"\n",
    "\n",
    "#Spatial Binning\n",
    "size=(8, 8)\n",
    "SB_colorspace = \"RGB\"\n",
    "\n",
    "#HOG Params\n",
    "HOG_colorspace = \"RGB\"\n",
    "orient = 8\n",
    "pix_per_cell = 16\n",
    "cells_per_block = 2\n",
    "blk_Norm = \"L2-Hys\"\n",
    "TransformSqrt = True\n",
    "feat_vec = True\n",
    "HOG_Ch_Idx = \"All\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return preprocessing.normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFeatures(img,debug=False,ReturnSizes=False):\n",
    "    \n",
    "    hist_feat = []\n",
    "    SB_feat = []\n",
    "    hog_feat = []\n",
    "    \n",
    "    hist_feat_shape = 0\n",
    "    SB_feat_shape   = 0\n",
    "    hog_feat_shape  = 0\n",
    "    \n",
    "    histrange = [0,255]\n",
    "    \n",
    "    if CHist_EN == True:\n",
    "        #Extract Color Hitogram Features\n",
    "        if Hist_colorspace == \"HSV\":\n",
    "            hist_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif Hist_colorspace == \"HLS\":\n",
    "            hist_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif Hist_colorspace == \"LAB\":\n",
    "            hist_image = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        elif Hist_colorspace == \"YUV\":\n",
    "            hist_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif Hist_colorspace == \"LUV\":\n",
    "            hist_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif Hist_colorspace == \"YCrCb\":\n",
    "            hist_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else: #Assume RGB No action needed\n",
    "            hist_image = np.copy(img)\n",
    "        \n",
    "        if CS_Ch_Idx != \"All\":\n",
    "            hist_feat = cv2.calcHist(hist_image,[CS_Ch_Idx],None,histSize,histrange)\n",
    "        else:\n",
    "            hist_feat = []\n",
    "            for Ch_Idx in range(hist_image.shape[2]):\n",
    "                hist_feat.append(cv2.calcHist(hist_image,[Ch_Idx],None,histSize,histrange))\n",
    "        \n",
    "        hist_feat = np.ravel(hist_feat).reshape(1, -1)\n",
    "\n",
    "        if debug == True:\n",
    "            print(\"Histogram\")\n",
    "            print(\"Before Normalize\")\n",
    "            print(hist_feat.shape)\n",
    "            print(hist_feat)\n",
    "        \n",
    "        if Nrmlz == True:\n",
    "            hist_feat = normalize(hist_feat)\n",
    "            if debug == True:\n",
    "                print(\"After Normalize\")\n",
    "                print(hist_feat.shape)\n",
    "                print(hist_feat)\n",
    "                \n",
    "        hist_feat = hist_feat[0]\n",
    "        hist_feat_shape = hist_feat.shape\n",
    "        \n",
    "    if SB_EN == True:\n",
    "        #Extract Spatial Binning Features\n",
    "        if Hist_colorspace == \"HSV\":\n",
    "            SB_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif Hist_colorspace == \"HLS\":\n",
    "            SB_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif Hist_colorspace == \"LAB\":\n",
    "            SB_image = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        elif Hist_colorspace == \"YUV\":\n",
    "            SB_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif Hist_colorspace == \"LUV\":\n",
    "            SB_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif Hist_colorspace == \"YCrCb\":\n",
    "            SB_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else: #Assume RGB No action needed\n",
    "            SB_image = np.copy(img)\n",
    "        \n",
    "        SB_feat = cv2.resize(SB_image, size).ravel().reshape(1, -1).astype(np.float64)\n",
    "\n",
    "        if debug == True:\n",
    "            print(\"Spatial Binning\")\n",
    "            print(\"Before Normalize\")\n",
    "            print(SB_feat.shape)\n",
    "            print(SB_feat)\n",
    "        \n",
    "        if Nrmlz == True:\n",
    "            SB_feat = normalize(SB_feat)\n",
    "            if debug == True:\n",
    "                print(\"After Normalize\")\n",
    "                print(SB_feat.shape)\n",
    "                print(SB_feat)\n",
    "                \n",
    "        SB_feat = SB_feat[0]\n",
    "        SB_feat_shape = SB_feat.shape\n",
    "    \n",
    "    if HOG_EN == True:\n",
    "        #Extract HOG Features\n",
    "        if HOG_colorspace == \"HSV\":\n",
    "            hog_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif HOG_colorspace == \"HLS\":\n",
    "            hog_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif HOG_colorspace == \"LAB\":\n",
    "            hog_image = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        elif HOG_colorspace == \"YUV\":\n",
    "            hog_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif HOG_colorspace == \"LUV\":\n",
    "            hog_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif HOG_colorspace == \"YCrCb\":\n",
    "            hog_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        else: #Assume RGB No action needed\n",
    "            hog_image = np.copy(img)\n",
    "        \n",
    "        if HOG_Ch_Idx != \"All\":\n",
    "            hog_feat = get_hog_features_demo(\n",
    "                img[:,:,HOG_Ch_Idx],\n",
    "                orient,\n",
    "                pix_per_cell,\n",
    "                cells_per_block,\n",
    "                blk_Norm,\n",
    "                visualize=False,\n",
    "                trns_sqrt=TransformSqrt,\n",
    "                feature_vec=True)\n",
    "        else:\n",
    "            for Ch_Idx in range(hog_image.shape[2]):\n",
    "                hog_feat.append(get_hog_features_demo(\n",
    "                    img[:,:,Ch_Idx],\n",
    "                    orient,\n",
    "                    pix_per_cell,\n",
    "                    cells_per_block,\n",
    "                    blk_Norm,\n",
    "                    visualize=False,\n",
    "                    trns_sqrt=TransformSqrt,\n",
    "                    feature_vec=True))\n",
    "        \n",
    "        hog_feat = np.ravel(hog_feat).reshape(1, -1)\n",
    "        \n",
    "        if debug == True:\n",
    "            print(\"HOG\")\n",
    "            print(\"Before Normalize\")\n",
    "            print(hog_feat.shape)\n",
    "            print(hog_feat)\n",
    "        \n",
    "        if Nrmlz == True:\n",
    "            hog_feat = normalize(hog_feat)\n",
    "            if debug == True:\n",
    "                print(\"After Normalize\")\n",
    "                print(hog_feat.shape)\n",
    "                print(hog_feat)\n",
    "                \n",
    "        hog_feat = hog_feat[0]\n",
    "        hog_feat_shape = hog_feat.shape\n",
    "    \n",
    "    if debug == True:\n",
    "        print(\"Before Concatenation\")\n",
    "        print(hist_feat)\n",
    "        print(SB_feat)\n",
    "        print(hog_feat)\n",
    "    \n",
    "    features = np.hstack((hist_feat, SB_feat, hog_feat))\n",
    "    \n",
    "    if debug == True:\n",
    "        print(\"Output\")\n",
    "        print(len(features))\n",
    "        print(features)\n",
    "    \n",
    "    #features = np.ravel(features)\n",
    "    \n",
    "    #if debug == True:\n",
    "        #print(features.shape)\n",
    "        #print(features)\n",
    "\n",
    "    if ReturnSizes == False:\n",
    "        return features\n",
    "    else:\n",
    "        return (hist_feat_shape, \n",
    "                SB_feat_shape, \n",
    "                hog_feat_shape, \n",
    "                features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Feature Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CarImageIndex = 0\n",
    "#CarImageIndex = randint(0, len(CarImageSet))\n",
    "HOGCarImage = [CarImageSet[CarImageIndex][imgPxlVal]]\n",
    "HOGCarImageLabel = [CarImageSet[CarImageIndex][img_Label]]\n",
    "\n",
    "pltImages(HOGCarImage, HOGCarImageLabel, 1, 1)\n",
    "Test = extractFeatures(HOGCarImage[0],\n",
    "                       debug=False,\n",
    "                       ReturnSizes=True)\n",
    "print(Test[0])\n",
    "print(Test[1])\n",
    "print(Test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expolre Different parameters as discussed in the sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PTNormalize      = 0\n",
    "PTCHist_EN       = 1\n",
    "PTCHist_BCnt     = 2\n",
    "PTCHist_CSpace   = 3\n",
    "PTCHist_Ch_Idx   = 4\n",
    "PTSB_EN          = 5\n",
    "PTSB_Size        = 6\n",
    "PTSB_CSpace      = 7\n",
    "PTHOG_EN         = 8\n",
    "PTHOG_OrientCnt  = 9\n",
    "PTHOG_Px_Per_Cl  = 10\n",
    "PTHOG_Cl_Per_Blk = 11\n",
    "PTHOG_Blk_Nrmlz  = 12\n",
    "PTHOG_Trnsf_Sqrt = 13\n",
    "PTHOG_CSpace     = 14\n",
    "PTHOG_Ch_Indx    = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ParameterTuning(SaveModel = False):\n",
    "    global CHist_EN\n",
    "    global SB_EN\n",
    "    global HOG_EN\n",
    "    global Nrmlz\n",
    "    global histSize\n",
    "    global Hist_colorspace\n",
    "    global CS_Ch_Idx\n",
    "    global size\n",
    "    global SB_colorspace\n",
    "    global HOG_colorspace\n",
    "    global orient\n",
    "    global pix_per_cell\n",
    "    global cells_per_block\n",
    "    global blk_Norm\n",
    "    global TransformSqrt\n",
    "    global HOG_Ch_Idx\n",
    "    \n",
    "    \n",
    "    SearchTrials=[\n",
    "        [True ,True ,[64],\"LUV\",\"All\",True ,(16,16),\"LUV\",True ,8,16,2,\"L2\",True ,\"LUV\",\"All\"], # 2\n",
    "    ]\n",
    "\n",
    "    for cnt in range(0,10):\n",
    "        for idx in range(0, len(SearchTrials)):\n",
    "            CHist_EN  = SearchTrials[idx][PTCHist_EN]\n",
    "            SB_EN     = SearchTrials[idx][PTSB_EN]\n",
    "            HOG_EN    = SearchTrials[idx][PTHOG_EN]\n",
    "            Nrmlz     = SearchTrials[idx][PTNormalize]\n",
    "            histSize  = SearchTrials[idx][PTCHist_BCnt]\n",
    "            Hist_colorspace = SearchTrials[idx][PTCHist_CSpace]\n",
    "            CS_Ch_Idx = SearchTrials[idx][PTCHist_Ch_Idx]\n",
    "            size      = SearchTrials[idx][PTSB_Size]\n",
    "            SB_colorspace   = SearchTrials[idx][PTSB_CSpace]\n",
    "            HOG_colorspace  = SearchTrials[idx][PTHOG_CSpace]\n",
    "            orient    = SearchTrials[idx][PTHOG_OrientCnt]\n",
    "            pix_per_cell    = SearchTrials[idx][PTHOG_Px_Per_Cl]\n",
    "            cells_per_block = SearchTrials[idx][PTHOG_Cl_Per_Blk]\n",
    "            blk_Norm  = SearchTrials[idx][PTHOG_Blk_Nrmlz]\n",
    "            TransformSqrt   = SearchTrials[idx][PTHOG_Trnsf_Sqrt]\n",
    "            HOG_Ch_Idx= SearchTrials[idx][PTHOG_Ch_Indx]\n",
    "\n",
    "            #Test = extractFeatures(HOGCarImage[0])\n",
    "\n",
    "            #start_time = time.time()\n",
    "            \n",
    "            lCar_features = []\n",
    "            lNonCar_features = []\n",
    "\n",
    "            for image in CarImageSet:\n",
    "                COut = extractFeatures(image[imgPxlVal], ReturnSizes=True)\n",
    "                lCar_features.append(COut[3])\n",
    "\n",
    "            for image in NonCarImageSet:\n",
    "                NCOut = extractFeatures(image[imgPxlVal], ReturnSizes=True)\n",
    "                lNonCar_features.append(NCOut[3])\n",
    "\n",
    "            lFeatureSet = np.vstack((lCar_features, lNonCar_features)).astype(np.float64)\n",
    "            lLbaelSet = np.hstack((np.ones(len(lCar_features)), np.zeros(len(lNonCar_features))))\n",
    "\n",
    "            #lrand_state = 20\n",
    "            lrand_state = np.random.randint(0, 100)\n",
    "            lFeature_train, lFeature_test, lLabel_train, lLabel_test = train_test_split(lFeatureSet, lLbaelSet, test_size=0.2, random_state=lrand_state)\n",
    "            \n",
    "            lFeature_scaler = StandardScaler().fit(lFeature_train)\n",
    "            lScaled_FeatureTrainSet = lFeature_scaler.transform(lFeature_train)\n",
    "            lScaled_FeatureTestSet = lFeature_scaler.transform(lFeature_test)\n",
    "\n",
    "            clf = TrainLinearSVCModel(lScaled_FeatureTrainSet, lLabel_train)\n",
    "            #clf = TrainModel_WithParameterSearch(lFeature_train, lLabel_train)\n",
    "            \n",
    "            if SaveModel == True:\n",
    "                Name = \"TrainedModel\" + str(cnt) + \".pkl\"\n",
    "                SaveModelFunc(clf, Name)\n",
    "\n",
    "            start_time = time.time()\n",
    "            \n",
    "            acc = clf.score(lScaled_FeatureTestSet, lLabel_test)\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            print(\"Param Set(\",idx,\") result in acc of \",acc,\" CH Feat cnt=\",COut[0],\" SB Feat cnt=\",COut[1],\" HOG Feat cnt=\",COut[2],\" In time:\",elapsed_time)\n",
    "            #print(\"Param value\", clf.best_params_)\n",
    "    \n",
    "ParameterTuning(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Feature Extraction Parameters\n",
    "ParamList = [True ,True ,[48],\"LUV\",\"All\",True ,(8,8),\"LUV\",True ,8,16,4,\"L2\",True ,\"LUV\",\"All\"]\n",
    "\n",
    "CHist_EN  = ParamList[PTCHist_EN]\n",
    "SB_EN     = ParamList[PTSB_EN]\n",
    "HOG_EN    = ParamList[PTHOG_EN]\n",
    "Nrmlz     = ParamList[PTNormalize]\n",
    "histSize  = ParamList[PTCHist_BCnt]\n",
    "Hist_colorspace = ParamList[PTCHist_CSpace]\n",
    "CS_Ch_Idx = ParamList[PTCHist_Ch_Idx]\n",
    "size      = ParamList[PTSB_Size]\n",
    "SB_colorspace   = ParamList[PTSB_CSpace]\n",
    "HOG_colorspace  = ParamList[PTHOG_CSpace]\n",
    "orient    = ParamList[PTHOG_OrientCnt]\n",
    "pix_per_cell    = ParamList[PTHOG_Px_Per_Cl]\n",
    "cells_per_block = ParamList[PTHOG_Cl_Per_Blk]\n",
    "blk_Norm  = ParamList[PTHOG_Blk_Nrmlz]\n",
    "TransformSqrt   = ParamList[PTHOG_Trnsf_Sqrt]\n",
    "HOG_Ch_Idx= ParamList[PTHOG_Ch_Indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car Feature Collected\n",
      "Non Car Feature Collected\n"
     ]
    }
   ],
   "source": [
    "Car_features = []\n",
    "NonCar_features = []\n",
    "\n",
    "for image in CarImageSet:\n",
    "    Car_features.append(extractFeatures(image[imgPxlVal],\n",
    "                                        debug=False))\n",
    "print(\"Car Feature Collected\")\n",
    "\n",
    "for image in NonCarImageSet:\n",
    "    NonCar_features.append(extractFeatures(image[imgPxlVal],\n",
    "                                        debug=False))\n",
    "print(\"Non Car Feature Collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FeatureSet = np.vstack((Car_features, NonCar_features)).astype(np.float64)\n",
    "LbaelSet = np.hstack((np.ones(len(Car_features)), np.zeros(len(NonCar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand_state = 20\n",
    "#rand_state = np.random.randint(0, 100)\n",
    "Feature_train, Feature_test, Label_train, Label_test = train_test_split(FeatureSet, LbaelSet, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Feature_scaler = StandardScaler().fit(Feature_train)\n",
    "Scaled_FeatureTrainSet = Feature_scaler.transform(Feature_train)\n",
    "Scaled_FeatureTestSet = Feature_scaler.transform(Feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0421702503439\n",
      "0.0488706113213\n",
      "-8.92215341759e-16\n",
      "1.0\n",
      "-0.00166202867483\n",
      "0.999170954107\n"
     ]
    }
   ],
   "source": [
    "print(FeatureSet.mean())\n",
    "print(FeatureSet.std())\n",
    "print(Scaled_FeatureTrainSet.mean())\n",
    "print(Scaled_FeatureTrainSet.std())\n",
    "print(Scaled_FeatureTestSet.mean())\n",
    "print(Scaled_FeatureTestSet.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainLinearSVCModel(feat, label):\n",
    "    svc = LinearSVC()\n",
    "    svc.fit(feat, label)\n",
    "\n",
    "    return svc\n",
    "\n",
    "def TrainModel_WithParameterSearch(feat, label):\n",
    "    parameters = {'C':[0.1, 100]}\n",
    "\n",
    "    svc = LinearSVC()\n",
    "    clf = GridSearchCV(svc, parameters)\n",
    "    clf.fit(feat, label)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def TrainSVCModel(feat, label):\n",
    "    svc = SVC(kernel='linear')\n",
    "    svc.fit(feat, label)\n",
    "\n",
    "    return svc\n",
    "\n",
    "#below code is obtained from http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "def SaveModelFunc(clf, Name='TrainedModel.pkl'):\n",
    "    s = pickle.dumps(clf)\n",
    "    joblib.dump(clf, Name)\n",
    "\n",
    "def LoadModelFunc(Name='TrainedModel.pkl'):\n",
    "    return joblib.load(Name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "clf = TrainLinearSVCModel(Feature_train, Label_train)\n",
    "SaveModelFunc(clf, \"ClassifierWithFeatureCount_720.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load Trained Model\")\n",
    "\n",
    "clf = LoadModelFunc(Name=\"TrainedModel9.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of SVC =  0.92454954955\n",
      "My SVC predicts:  [ 1.] for label:  0.0\n",
      "My SVC predicts:  [ 0.] for label:  0.0\n",
      "My SVC predicts:  [ 1.] for label:  1.0\n",
      "My SVC predicts:  [ 0.] for label:  0.0\n",
      "My SVC predicts:  [ 0.] for label:  0.0\n",
      "My SVC predicts:  [ 0.] for label:  0.0\n",
      "My SVC predicts:  [ 0.] for label:  0.0\n",
      "My SVC predicts:  [ 1.] for label:  1.0\n",
      "My SVC predicts:  [ 1.] for label:  1.0\n",
      "My SVC predicts:  [ 0.] for label:  0.0\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy of SVC = ', clf.score(Scaled_FeatureTestSet, Label_test))\n",
    "\n",
    "for i in range(10):\n",
    "    print('My SVC predicts: ', clf.predict(Scaled_FeatureTestSet[i].reshape(1, -1)), 'for label: ', Label_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ok We now have selected our tuned parameters for Liner SVM, Moving on to Sliding Windows Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inpath  = \"./test_images\"\n",
    "TestimagesPaths = os.listdir(Inpath)\n",
    "\n",
    "TestImages = CollectImages(Inpath + '/', TestimagesPaths, isLabeled = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        color = (np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255))\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, \n",
    "                      bbox[0], \n",
    "                      bbox[1], \n",
    "                      color, \n",
    "                      thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nearly the same function in lessons\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5), debug=False):\n",
    "    if x_start_stop == [None, None]:\n",
    "        x_start_stop = [0, img.shape[1]]\n",
    "    if y_start_stop == [None, None]:\n",
    "        y_start_stop = [0, img.shape[0]]\n",
    "    \n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    \n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    \n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step)\n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step)\n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    \n",
    "    # Loop through finding x and y window positions\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    if debug == True:\n",
    "        return (window_list, nx_windows, ny_windows)\n",
    "    else:\n",
    "        return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = TestImages[0].shape[0]\n",
    "x = TestImages[0].shape[1]\n",
    "\n",
    "x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "y_s_s = [np.int(y * 0.6), np.int(y * 0.7)]\n",
    "\n",
    "windows= slide_window(TestImages[0], x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                        xy_window=(32, 32), xy_overlap=(0.5, 0.5), debug=True)\n",
    "\n",
    "x_dif = x_s_s[1] - x_s_s[0]\n",
    "y_dif = y_s_s[1] - y_s_s[0]\n",
    "\n",
    "print(windows[1])\n",
    "print(windows[2])\n",
    "print(str(x_s_s) + \" \" + str(x_dif) + \" \" + str((x_dif/windows[1])))\n",
    "print(str(y_s_s) + \" \" + str(y_dif) + \" \" + str((y_dif/windows[2])))\n",
    "\n",
    "window_img = draw_boxes(TestImages[0], windows[0], thick=6)\n",
    "\n",
    "pltImages([window_img], [\"vis_labels\"], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for image in TestImages:\n",
    "    y = image.shape[0]\n",
    "    x = image.shape[1]\n",
    "    x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "    y_s_s = [np.int(y * 0.5), np.int(y * 0.95)]\n",
    "    windows= slide_window(image, x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                          xy_window=(64, 64), xy_overlap=(0.5, 0.5), debug=False)\n",
    "    window_img = draw_boxes(image, windows, thick=6)\n",
    "    #pltImages([window_img], [\"vis_labels\"], 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Check_Frame_For_Car(image, windows):\n",
    "    \n",
    "    detected_box = []\n",
    "    \n",
    "    for window in windows:\n",
    "        img = cv2.resize(image[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))   \n",
    "        image_Features = extractFeatures(img)\n",
    "        scaled_image_Features = Feature_scaler.transform(image_Features.reshape(1, -1))\n",
    "        #print(scaled_image_Features.shape)\n",
    "        isCar = clf.predict(scaled_image_Features)\n",
    "        #print(isCar)\n",
    "        if isCar == True:\n",
    "            detected_box.append(window)\n",
    "    return detected_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = 720\n",
    "x = 1280\n",
    "\n",
    "x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "y_s_s = [np.int(y * 0.6), np.int(y * 0.7)]\n",
    "\n",
    "windows_32 = slide_window(image, x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                          xy_window=(64, 64), xy_overlap=(0.7, 0.7), debug=False)\n",
    "\n",
    "x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "y_s_s = [np.int(y * 0.5), np.int(y * 0.75)]\n",
    "\n",
    "windows_64 = slide_window(image, x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                          xy_window=(64, 64), xy_overlap=(0.7, 0.7), debug=False)\n",
    "\n",
    "x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "y_s_s = [np.int(y * 0.5), np.int(y * 0.95)]\n",
    "\n",
    "windows_128 = slide_window(image, x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                           xy_window=(128, 128), xy_overlap=(0.7, 0.7), debug=False)\n",
    "\n",
    "OutputImg = []\n",
    "counter = 0\n",
    "\n",
    "for image in TestImages:\n",
    "    DBox = []\n",
    "    \n",
    "    print(counter)\n",
    "    start_time = time.time()\n",
    "    Boxes1 = Check_Frame_For_Car(image, windows_32)\n",
    "    print(time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "    Boxes2 = Check_Frame_For_Car(image, windows_64)\n",
    "    print(time.time() - start_time)\n",
    "    start_time = time.time()\n",
    "    Boxes3 = Check_Frame_For_Car(image, windows_128)\n",
    "    print(time.time() - start_time)\n",
    "    \n",
    "    for box in Boxes1:\n",
    "        DBox.append(box)\n",
    "    for box in Boxes2:\n",
    "        DBox.append(box)\n",
    "    for box in Boxes3:\n",
    "        DBox.append(box)\n",
    "    \n",
    "    OutputImg.append(draw_boxes(image, DBox, thick=6))\n",
    "\n",
    "pltImages(OutputImg, \"\", 6, 1, 20, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add heat map support as described in lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    for box in bbox_list:\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "OutputImg = []\n",
    "\n",
    "for image in TestImages:\n",
    "    DBox = []\n",
    "    \n",
    "    Boxes1 = Check_Frame_For_Car(image, windows_32)\n",
    "    Boxes2 = Check_Frame_For_Car(image, windows_64)\n",
    "    Boxes3 = Check_Frame_For_Car(image, windows_128)\n",
    "    \n",
    "    for box in Boxes1:\n",
    "        DBox.append(box)\n",
    "    for box in Boxes2:\n",
    "        DBox.append(box)\n",
    "    for box in Boxes3:\n",
    "        DBox.append(box)\n",
    "        \n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat, DBox)\n",
    "    heat = apply_threshold(heat,3)\n",
    "    labels = label(heat)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    pltImages([draw_boxes(image, DBox, thick=6), heat, draw_img], \"\", 1, 3)\n",
    "    \n",
    "    #OutputImg.append(draw_boxes(image, DBox, thick=6))\n",
    "\n",
    "#pltImages(OutputImg, \"\", 6, 1, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from scipy.ndimage.measurements import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 720\n",
    "x = 1280\n",
    "\n",
    "x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "y_s_s = [np.int(y * 0.6), np.int(y * 0.7)]\n",
    "\n",
    "windows_32 = slide_window(image, x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                          xy_window=(64, 64), xy_overlap=(0.7, 0.7), debug=False)\n",
    "\n",
    "x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "y_s_s = [np.int(y * 0.5), np.int(y * 0.75)]\n",
    "\n",
    "windows_64 = slide_window(image, x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                          xy_window=(64, 64), xy_overlap=(0.8, 0.8), debug=False)\n",
    "\n",
    "x_s_s = [np.int(x * 0.4), np.int(x * 1.00)]\n",
    "y_s_s = [np.int(y * 0.5), np.int(y * 0.95)]\n",
    "\n",
    "windows_128 = slide_window(image, x_start_stop=x_s_s, y_start_stop=y_s_s, \n",
    "                           xy_window=(128, 128), xy_overlap=(0.8, 0.8), debug=False)\n",
    "\n",
    "def ProcessVideoFrame(image):\n",
    "    Boxes1 = Check_Frame_For_Car(image, windows_32)\n",
    "    Boxes2 = Check_Frame_For_Car(image, windows_64)\n",
    "    Boxes3 = Check_Frame_For_Car(image, windows_128)\n",
    "    \n",
    "    DBox = []\n",
    "    \n",
    "    for box in Boxes1:\n",
    "        DBox.append(box)\n",
    "    for box in Boxes2:\n",
    "        DBox.append(box)\n",
    "    for box in Boxes3:\n",
    "        DBox.append(box)\n",
    "    \n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat, DBox)\n",
    "    heat = apply_threshold(heat,6)\n",
    "    labels = label(heat)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_output = 'test_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "project_clip = clip1.fl_image(ProcessVideoFrame)\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_out.mp4\n",
      "[MoviePy] Writing video project_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1260/1261 [1:09:24<00:03,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_out.mp4 \n",
      "\n",
      "Wall time: 1h 9min 26s\n"
     ]
    }
   ],
   "source": [
    "project_output = 'project_video_out.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_clip = clip1.fl_image(ProcessVideoFrame)\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
